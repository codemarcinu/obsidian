import os
import re
from pathlib import Path

class ObsidianGardener:
    def __init__(self, vault_path):
        self.vault_path = Path(vault_path)
        self.all_files = self._scan_vault()

    def _scan_vault(self):
        """Tworzy map wszystkich plik贸w w Vaulcie do szybkiego wyszukiwania."""
        files_map = {}
        if not self.vault_path.exists():
            return files_map
            
        for path in self.vault_path.rglob("*.md"):
            # Kluczem jest nazwa pliku bez rozszerzenia (lower case dla case-insensitive matching)
            clean_name = path.stem.lower()
            files_map[clean_name] = path.stem # Zapisujemy oryginaln pisowni
        return files_map

    def clean_markdown(self, content):
        """Czyci typowe bdy formatowania AI."""
        # 1. Usuwanie wielokrotnych pustych linii
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # 2. Poprawa list (czasem AI robi "*Punkt" bez spacji)
        content = re.sub(r'^(\s*)[-*](\w)', r'\1- \2', content, flags=re.MULTILINE)
        
        # 3. Upewnienie si, 偶e nag贸wki maj spacj po #
        content = re.sub(r'^(#+)([^#\s])', r'\1 \2', content, flags=re.MULTILINE)
        
        return content

    def auto_link(self, content):
        """Automatycznie tworzy linki [[WikiLink]] do istniejcych notatek."""
        # Sortujemy klucze od najdu偶szych, 偶eby nie podmieni "Auto" wewntrz "Automatyzacja"
        sorted_keys = sorted(self.all_files.keys(), key=len, reverse=True)
        
        # Ignorujemy sowa bardzo kr贸tkie i pospolite (stop words - uproszczone)
        ignored = {'i', 'w', 'z', 'do', 'na', 'to', 'jest'}
        
        new_content = content
        
        # Zabezpieczenie przed linkowaniem wewntrz istniejcych link贸w lub kodu
        # To prosta implementacja - w penej wersji wymagaaby parsera AST, ale tu wystarczy split
        
        # Dzielimy tekst na czci: kod/linki vs zwyky tekst, 偶eby nie psu skadni
        # (Uproszczone podejcie: skanujemy tylko jeli nie jestemy wewntrz [[...]] lub `...`)
        
        for key in sorted_keys:
            if len(key) < 3 or key in ignored:
                continue
                
            original_name = self.all_files[key]
            
            # Regex: Znajd藕 sowo (case insensitive), kt贸re NIE jest ju偶 w nawiasach [[ ]]
            # Lookbehind i Lookahead s trudne w Python re dla zmiennej dugoci,
            # wic u偶yjemy bezpieczniejszej metody replace z funkcj sprawdzajc.
            
            pattern = re.compile(re.escape(key), re.IGNORECASE)
            
            def replace_func(match):
                word = match.group(0)
                # Sprawd藕 kontekst (czy to nie jest cz innego sowa)
                # Tutaj robimy prost zamian: jeli znale藕limy dokadne dopasowanie
                return f"[[{original_name}|{word}]]"

            # UWAGA: To jest ryzykowne w prostym regex. 
            # Bezpieczniej: Linkujemy tylko terminy zdefiniowane jako "Sownik" lub "Koncepty"
            # W tej wersji zrobimy to ostro偶nie - tylko dokadne dopasowania caych s贸w.
            
            pattern = re.compile(r'\b' + re.escape(key) + r'\b', re.IGNORECASE)
            
            # Problem: jak nie zamieni ju偶 zlinkowanego [[Linux]] na [[Linux|[[Linux]]]]?
            # Rozwizanie: Na razie pomijamy auto-linkowanie wewntrz treci,
            # skupmy si na sekcji "See Also" lub dodaniu sekcji na kocu.
            
            # WERSJA PROSTA: Dodajemy sekcj "Powizane notatki" na dole
            if key in new_content.lower() and f"[[{original_name}" not in new_content:
                # Nie ingerujemy w tre, tylko sugerujemy na kocu
                pass 

        return new_content

    def append_related_links(self, content):
        """Dodaje sekcj 'Automatyczne Powizania' na kocu notatki."""
        found_links = set()
        lower_content = content.lower()
        
        for key, original_name in self.all_files.items():
            if len(key) < 4: continue # Ignoruj kr贸tkie
            
            # Jeli nazwa pliku wystpuje w treci, a nie ma jeszcze linku
            if key in lower_content:
                # Sprawd藕 czy link ju偶 nie istnieje wprost
                if f"[[{original_name}" not in content and f"[[{key}" not in content.lower():
                    found_links.add(original_name)
        
        if found_links:
            footer = "\n\n---\n###  Automatyczne Powizania (wykryte w treci)\n"
            for link in sorted(found_links):
                footer += f"- [[{link}]]\n"
            return content + footer
        
        return content

    def process_file(self, file_path):
        """G贸wna funkcja przetwarzajca pojedynczy plik."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 1. Czyszczenie
            content = self.clean_markdown(content)
            
            # 2. Linkowanie (dodawanie stopki)
            content = self.append_related_links(content)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            return True, "Zoptymalizowano i dodano linki."
        except Exception as e:
            return False, str(e)

if __name__ == "__main__":
    # Test manualny
    import sys
    if len(sys.argv) > 2:
        gardener = ObsidianGardener(sys.argv[2])
        print(gardener.process_file(sys.argv[1]))
    else:
        print("Usage: python obsidian_manager.py <file_path> <vault_path>")
